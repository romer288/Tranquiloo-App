You're running into a classic mobile/PWA gotcha: on iOS (and some Android builds), speechSynthesis won’t start until there’s a real user gesture in that tab/window. In installed PWAs (“standalone” mode) iOS also often returns getVoices() = [] and never fires onvoiceschanged until after a gesture. Because your auto-speak runs right after the AI responds (no tap yet), the engine never “unlocks,” so you hear nothing.

Here’s a tight, surgical fix set:

1) Gate auto-speak behind a one-time “speech unlocked” flag

In ChatContainer.tsx, add a tiny unlock state and prime function. Only allow the auto-speak effect to run after the user has tapped anything once.

// ChatContainer.tsx (top-level component state)
const [speechUnlocked, setSpeechUnlocked] = React.useState(false);

// Prime iOS/PWA speech on first real gesture
const unlockSpeech = React.useCallback(() => {
  if (speechUnlocked) return;
  try {
    if ('speechSynthesis' in window) {
      // 1) cancel any stuck state
      window.speechSynthesis.cancel();
      // 2) speak a zero-length utterance to "unlock"
      const u = new SpeechSynthesisUtterance('');
      u.onend = () => setSpeechUnlocked(true);
      u.onerror = () => setSpeechUnlocked(true);
      window.speechSynthesis.speak(u);
    } else {
      setSpeechUnlocked(true);
    }
  } catch {
    setSpeechUnlocked(true);
  }
}, [speechUnlocked]);

// Add a global "first gesture" listener (mounted once)
React.useEffect(() => {
  const prime = () => unlockSpeech();
  window.addEventListener('pointerdown', prime, { once: true });
  window.addEventListener('keydown', prime, { once: true });
  return () => {
    window.removeEventListener('pointerdown', prime);
    window.removeEventListener('keydown', prime);
  };
}, [unlockSpeech]);


Now, short-circuit your auto-speak effect until unlocked:

// in the auto-speak useEffect condition
if (!speechUnlocked) {
  // console.log('🔊 Auto-speak blocked until speech unlocked by user gesture');
  return;
}


Optional: add a tiny banner/button the first time on mobile: “Tap to enable voice”. On click, call unlockSpeech().

2) Prefer local voices; don’t depend on onvoiceschanged in PWA

In useSpeechSynthesis.tsx, iOS PWAs often never fire onvoiceschanged. Make two tweaks:

Prefer local voices (network voices can fail in PWAs).

If getVoices() is empty, don’t wait—speak with system default (skip setting utterance.voice).

// after: let voices = window.speechSynthesis.getVoices();
if (voices.length === 0) {
  // Try to nudge, but do NOT block if still empty
  const dummy = new SpeechSynthesisUtterance('');
  try {
    window.speechSynthesis.speak(dummy);
    window.speechSynthesis.cancel();
    voices = window.speechSynthesis.getVoices();
  } catch {}
}

// When selecting voice:
const voice = findBestVoiceForLanguage(language);
// Prefer local voices if available
const chosen = voice && voice.localService ? voice : (voices.find(v => v.lang.startsWith(utterance.lang) && v.localService) || voice);
if (chosen) utterance.voice = chosen; // else let system default pick


And don’t rely on onvoiceschanged to set supported—keep your current detection, but don’t gate speaking on that event firing.

3) Make sure you only auto-speak after any user action

You already stop speech when the user types or starts listening—good. Add unlockSpeech() to places you know are user-initiated:

The Send button

The Voice ON/OFF toggle

The mic toggle

Example in ChatInput.tsx:

// Add prop: onUserGesture?: () => void;
// Call it from any button/typing handlers
const handleSendClick = () => {
  onUserGesture?.();  // 👈 add this
  if (inputText.trim()) onSendMessage();
};

<input
  onChange={(e) => {
    onUserGesture?.(); // 👈 add this (first keystroke unlocks)
    ...
  }}
/>

<Button onClick={() => { onUserGesture?.(); onToggleListening(); }} ... />


And in ChatContainer.tsx pass it down:

<ChatSection
  ...
  onUserGesture={unlockSpeech}
/>


(Or wire it through ChatInput if that’s where the handlers live.)

4) Resume/cancel safety on page lifecycle (iOS quirk)

Still in useSpeechSynthesis.tsx, add this tiny lifecycle stabilizer:

useEffect(() => {
  const onVis = () => {
    if (document.visibilityState === 'visible' && window.speechSynthesis?.paused) {
      try { window.speechSynthesis.resume(); } catch {}
    }
  };
  window.addEventListener('visibilitychange', onVis);
  window.addEventListener('pageshow', onVis);
  return () => {
    window.removeEventListener('visibilitychange', onVis);
    window.removeEventListener('pageshow', onVis);
  };
}, []);

5) MobileSpeechButton: resume before speaking

Quick harden:

setTimeout(() => {
  try { window.speechSynthesis.resume(); } catch {}
  window.speechSynthesis.speak(utterance);
}, 100);

Why this works

User-gesture unlock: Satisfies autoplay/voice policies so iOS actually starts the speech engine.

No onvoiceschanged dependency: PWAs frequently never fire it; we fall back to default voice.

Local voice preference: iOS PWAs sometimes block or fail network voices.

Lifecycle resume: iOS can randomly pause the engine when the app goes background/foreground.

After these changes, you should hear the agent on mobile (web and installed PWA). If you still don’t on iOS: confirm you’re not in Low Power Mode (can throttle speech), and test in Safari tab first (not home-screen PWA) to isolate a PWA-only issue.